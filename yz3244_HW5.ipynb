{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Lecture5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA and Logistic Classification and Feature Development for MNIST Image sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:48.522285Z",
     "start_time": "2018-03-02T02:53:43.783853Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from E4525_ML import mnist\n",
    "from E4525_ML.multiclass_logistic import LogisticGDClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T11:06:16.497625Z",
     "start_time": "2018-02-15T11:06:16.466372Z"
    }
   },
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:48.537898Z",
     "start_time": "2018-03-02T02:53:48.522285Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=458\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:48.561796Z",
     "start_time": "2018-03-02T02:53:48.537898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir=r\"../../raw/mnist/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 0 </div>\n",
    "Make sure to **update** the file `mnist.py` on the `E4525_ML` directory (new version posted on Canvas).\n",
    "\n",
    "You will need the **updated** version of that file to complete the last section of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.0 </div>\n",
    "Read MNIST data set and labels,  also read the MNMIST test data set and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:49.201245Z",
     "start_time": "2018-03-02T02:53:48.563202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "    images_filename=data_dir+\"train-images-idx3-ubyte.gz\"\n",
    "    labels_filename=data_dir+\"train-labels-idx1-ubyte.gz\"\n",
    "\n",
    "    test_images_filename=data_dir+\"t10k-images-idx3-ubyte.gz\"\n",
    "    test_labels_filename=data_dir+\"t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "    images=mnist.read_images(images_filename)\n",
    "    labels=mnist.read_labels(labels_filename)\n",
    "    \n",
    "    images_test=mnist.read_images(test_images_filename)\n",
    "    labels_test=mnist.read_labels(test_labels_filename)\n",
    "    \n",
    "    print(images.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T22:03:06.235419Z",
     "start_time": "2018-01-21T22:03:06.219795Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 1.2 </div>\n",
    "Use `skelearn`'s `train_test_split` function to separate the MNIST samples into  a 15% validation set and a  training sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:49.370644Z",
     "start_time": "2018-03-02T02:53:49.201245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 28, 28) (9000, 28, 28) (51000,) (9000,)\n"
     ]
    }
   ],
   "source": [
    "images_train,images_val,labels_train,labels_val=train_test_split(images,labels,test_size=0.15)\n",
    "print(images_train.shape,images_val.shape,labels_train.shape,labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T22:09:15.766264Z",
     "start_time": "2018-01-21T22:09:15.750639Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.1 </div>\n",
    "fit an LDA model on the training data set using `sklearns` `LinearDiscriminantAnalysis` classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:56.122416Z",
     "start_time": "2018-03-02T02:53:49.370644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51000, 784)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "X_train=images_train.reshape((images_train.shape[0],-1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model=LDA()\n",
    "sk_model.fit(X_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T23:22:08.665966Z",
     "start_time": "2018-02-27T23:22:08.656899Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.2 </div>\n",
    "Compute model accuracy on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:56.250935Z",
     "start_time": "2018-03-02T02:53:56.124604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87211764705882355"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sk_model.predict(X_train)==labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T23:22:33.457547Z",
     "start_time": "2018-02-27T23:22:33.449526Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 2.3 </div>\n",
    "Compute accuracy of the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:53:56.284022Z",
     "start_time": "2018-03-02T02:53:56.253442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86477777777777776"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val=images_val.reshape((images_val.shape[0],-1))\n",
    "np.mean(sk_model.predict(X_val)==labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 3.1 </div>\n",
    "\n",
    "Use the `LogisticGDClassifier` class from `E4525_ML.multiclass_logistic` module to fit a logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:18.808353Z",
     "start_time": "2018-03-02T02:53:56.286028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 Loss = 2371.93402487 Train_Accuracy 0.07 \n",
      "\t 10 Loss = 266.953052084 Train_Accuracy 0.92 \n",
      "\t 20 Loss = 259.981781374 Train_Accuracy 0.924 \n",
      "\t 30 Loss = 254.43186044 Train_Accuracy 0.926 \n",
      "\t 40 Loss = 242.487337851 Train_Accuracy 0.924 \n",
      "\t 50 Loss = 239.245801525 Train_Accuracy 0.935 \n",
      "\t 60 Loss = 256.877972816 Train_Accuracy 0.924 \n",
      "\t 70 Loss = 284.373788324 Train_Accuracy 0.922 \n",
      "\t 80 Loss = 217.9984568 Train_Accuracy 0.944 \n",
      "\t 90 Loss = 242.064030514 Train_Accuracy 0.946 \n",
      "\t 99 Loss = 218.246159941 Train_Accuracy 0.936 \n"
     ]
    }
   ],
   "source": [
    "from E4525_ML.multiclass_logistic import LogisticGDClassifier as Logis\n",
    "log_model=Logis()\n",
    "log_model.fit(X_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 3.2 </div>\n",
    "Compute model accuracy in the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:18.909580Z",
     "start_time": "2018-03-02T02:54:18.808353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93447058823529416"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(log_model.predict(X_train)==labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T11:10:43.634394Z",
     "start_time": "2018-02-28T11:10:43.627379Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 3.3 </div>\n",
    "Compute model accuracy in the valuation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:18.941595Z",
     "start_time": "2018-03-02T02:54:18.909580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157777777777778"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(log_model.predict(X_val)==labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering in one Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:18.953092Z",
     "start_time": "2018-03-02T02:54:18.945578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=50\n",
    "N_val=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:18.968123Z",
     "start_time": "2018-03-02T02:54:18.957105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 10*(1-4*(np.abs(np.abs(x)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:18.988127Z",
     "start_time": "2018-03-02T02:54:18.972126Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(N):\n",
    "    X=np.random.uniform(-2,2,N)\n",
    "    eta=f(X)\n",
    "    eta.shape\n",
    "    theta=1/(1+np.exp(-eta))\n",
    "    Y= np.random.uniform(0,1,N)>theta\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.22386687,  1.94009723, -1.468868  , -1.01121348,  0.90641874,\n",
       "       -0.32683951, -0.28904029,  0.90133992,  1.25263169,  0.19143293,\n",
       "        1.76843092,  1.17623794, -0.81947811,  0.10707658, -0.58869573,\n",
       "       -1.16302342,  1.98926495, -0.71309513,  1.77739197, -0.27188633,\n",
       "        1.06081216, -1.50050664,  1.18702852,  1.41192108,  1.84465139,\n",
       "       -1.93555988,  1.4984523 , -0.48976963, -1.39272073,  0.20397415,\n",
       "       -0.93569064, -0.77215659,  0.99958249,  0.98471474, -0.23990945,\n",
       "       -1.66209593, -0.07223514,  0.8410368 , -0.91840206,  1.31399206,\n",
       "       -0.58626123, -0.55390412, -0.673419  ,  1.60400415, -0.24098103,\n",
       "       -0.4793224 , -0.10693736, -0.43410016, -0.29290766,  0.69823331])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generate_sample(N)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 4.0 </div>\n",
    "Generate \n",
    "1. a training sample of variables $X$ and $Y$ with $N$ data samples\n",
    "2. a valuation set with   $N_{val}$ samples\n",
    "3. a test set with $N_{val}$ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:19.004123Z",
     "start_time": "2018-03-02T02:54:18.988127Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, Y_train = generate_sample(N)\n",
    "x_val, Y_val = generate_sample(N_val)\n",
    "x_test, Y_test = generate_sample(N_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:55:32.365942Z",
     "start_time": "2018-02-28T17:55:32.347942Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 4.1 </div>\n",
    "What is the proportion of positive class ($Y=1$) samples on the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:19.032124Z",
     "start_time": "2018-03-02T02:54:19.008125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80000000000000004"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Y_train==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:39:04.058942Z",
     "start_time": "2018-02-28T17:39:04.050942Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 4.2 </div>\n",
    "Write a function able to generate the feature matrix\n",
    "$$\n",
    "    H_{i,d}= h_d(x_i)\n",
    "$$\n",
    "for $i=1,\\dots N$ and $d=1,\\dots D$\n",
    "\n",
    "where the functions $h_d(x)$ are defined as \n",
    "$$\n",
    "    h_d(x) = x^d\n",
    "$$\n",
    "\n",
    "[HINT] be careful to include $h_D$ in the range of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:19.051637Z",
     "start_time": "2018-03-02T02:54:19.036124Z"
    }
   },
   "outputs": [],
   "source": [
    "def featurematrix(data, D):\n",
    "    K=data.shape[0]\n",
    "    feature = np.empty((K,D))\n",
    "    for i in range(K):\n",
    "        for d in range(0, D):\n",
    "            feature[i][d] = pow(data[i], d+1)\n",
    "    \n",
    "    return feature\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:42:00.116942Z",
     "start_time": "2018-02-28T17:42:00.110942Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 4.3 </div>\n",
    "1. Train  a logistic regression model (use sklearn `LogisticRegression` class) over the training data you already generated. \n",
    "2. Use the valuation set  to select the best value of $D$ using accuracy as selection criteria.\n",
    "3. Plot accuracy on the  training and valuation sets as a function of $D$.\n",
    "\n",
    "[HINT]\n",
    "1. You only need to consider the range $D=1,\\dots 10$.\n",
    "2. Remember to disable regularization by setting the parameter $C$ of the `LogisticRegression` class to a very large number.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:19.300275Z",
     "start_time": "2018-03-02T02:54:19.096174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:  1 Accuracy:  0.736\n",
      "D:  2 Accuracy:  0.736\n",
      "D:  3 Accuracy:  0.736\n",
      "D:  4 Accuracy:  0.855\n",
      "D:  5 Accuracy:  0.736\n",
      "D:  6 Accuracy:  0.736\n",
      "D:  7 Accuracy:  0.736\n",
      "D:  8 Accuracy:  0.736\n",
      "D:  9 Accuracy:  0.736\n",
      "D:  10 Accuracy:  0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic_model=LogisticRegression(C=1e30, multi_class=\"multinomial\",solver=\"sag\")\n",
    "for D in range(1,11):\n",
    "    train_feature = featurematrix(x_train, D)\n",
    "    logistic_model.fit(train_feature,Y_train)\n",
    "    val_feature = featurematrix(x_val, D)\n",
    "    val_pred=logistic_model.predict(val_feature)\n",
    "    print(\"D: \", D, \"Accuracy: \", np.mean(val_pred==Y_val))\n",
    "\n",
    "# We can see from the result that when D = 4, the accuracy is the highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 4.4 </div>\n",
    "Use the test set  to measure the accuracy for the optimal classifier you have found\n",
    "(do not use data from the  valuation set to train the classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:19.312275Z",
     "start_time": "2018-03-02T02:54:19.300275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95599999999999996"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model=LogisticRegression(C=1e30)\n",
    "train_feature = featurematrix(x_train, 4)\n",
    "logistic_model.fit(train_feature,Y_train)\n",
    "test_feature = featurematrix(x_test, 4)\n",
    "test_pred=logistic_model.predict(test_feature)\n",
    "np.mean(test_pred==Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for MNIST sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 5.1 </div>\n",
    "In this problem we will use `mnist.ImageFeatureModel` class to find the optimal number of orientations $\\theta$  of the oriented gradients\n",
    "features for the MNIST data set.\n",
    "\n",
    "1. use `mnist.ImageFeatureModel` to generate image oriented gradient features.\n",
    "2. use  `LogisticGDClassifier` as the base model\n",
    "3. set the block size to 4 ) this is to reduce memory use)\n",
    "4. select the best number of orientations by performing  5-Fold cross-validation on the full MNIST data set.\n",
    "5. Consider only [1,2,4,8] as possible values for the orientation\n",
    "6. Plot number of orientations vs validation accuracy\n",
    "\n",
    "[HINT] \n",
    "1. the `valiation_model` function below will be useful to perform cross-validation\n",
    "2. If you run into memory trouble (your computer crashes), reduce the size of the data set.\n",
    "Make sure to  indicate this clearly on your solution.\n",
    "3. This problem is computationally expensive, make sure to allocate time to resolve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:54:19.351788Z",
     "start_time": "2018-03-02T02:54:19.312275Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_model(model,K,X,Y):\n",
    "    folder=KFold(K,shuffle=True)\n",
    "    folds=folder.split(X,Y)\n",
    "    val_error=0.0\n",
    "    fold_count=0\n",
    "    for fold in folds:\n",
    "        train_idx,val_idx=fold\n",
    "        x_train=X[train_idx]\n",
    "        y_train=Y[train_idx]\n",
    "        x_val=X[val_idx]\n",
    "        y_val=Y[val_idx]     \n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred=model.predict(x_val)\n",
    "        val_err=np.mean(y_val==y_pred)\n",
    "        val_error+=val_err\n",
    "        fold_count+=1\n",
    "        print(fold_count,val_err)\n",
    "    return val_error/K\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:14:27.026220Z",
     "start_time": "2018-03-02T02:54:19.356299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 Loss = 2388.6717466 Train_Accuracy 0.123 \n",
      "\t 10 Loss = 101.567132172 Train_Accuracy 0.974 \n",
      "\t 20 Loss = 108.200190576 Train_Accuracy 0.969 \n",
      "\t 30 Loss = 107.034848477 Train_Accuracy 0.962 \n",
      "\t 40 Loss = 99.6739601263 Train_Accuracy 0.963 \n",
      "\t 50 Loss = 80.7404456935 Train_Accuracy 0.967 \n",
      "\t 60 Loss = 86.0237234208 Train_Accuracy 0.972 \n",
      "\t 70 Loss = 60.891146112 Train_Accuracy 0.977 \n",
      "\t 80 Loss = 73.0153536287 Train_Accuracy 0.974 \n",
      "\t 90 Loss = 93.5922380985 Train_Accuracy 0.97 \n",
      "\t 99 Loss = 73.9992439612 Train_Accuracy 0.978 \n",
      "1 0.968166666667\n",
      "\t 0 Loss = 2473.78984343 Train_Accuracy 0.119 \n",
      "\t 10 Loss = 118.479214471 Train_Accuracy 0.967 \n",
      "\t 20 Loss = 120.981832936 Train_Accuracy 0.963 \n",
      "\t 30 Loss = 89.7642579433 Train_Accuracy 0.974 \n",
      "\t 40 Loss = 150.644621158 Train_Accuracy 0.959 \n",
      "\t 50 Loss = 86.8415686286 Train_Accuracy 0.975 \n",
      "\t 60 Loss = 59.3527496484 Train_Accuracy 0.985 \n",
      "\t 70 Loss = 58.4929466785 Train_Accuracy 0.982 \n",
      "\t 80 Loss = 62.0274692707 Train_Accuracy 0.975 \n",
      "\t 90 Loss = 73.6858430843 Train_Accuracy 0.98 \n",
      "\t 99 Loss = 83.1632457461 Train_Accuracy 0.968 \n",
      "2 0.96575\n",
      "\t 0 Loss = 2365.01807764 Train_Accuracy 0.065 \n",
      "\t 10 Loss = 165.588449952 Train_Accuracy 0.951 \n",
      "\t 20 Loss = 114.069097575 Train_Accuracy 0.966 \n",
      "\t 30 Loss = 118.362080585 Train_Accuracy 0.962 \n",
      "\t 40 Loss = 75.5326456093 Train_Accuracy 0.977 \n",
      "\t 50 Loss = 92.3099715287 Train_Accuracy 0.98 \n",
      "\t 60 Loss = 82.4374864539 Train_Accuracy 0.981 \n",
      "\t 70 Loss = 85.7135801912 Train_Accuracy 0.971 \n",
      "\t 80 Loss = 89.5679738731 Train_Accuracy 0.971 \n",
      "\t 90 Loss = 70.2120278888 Train_Accuracy 0.971 \n",
      "\t 99 Loss = 76.497686933 Train_Accuracy 0.973 \n",
      "3 0.965\n",
      "\t 0 Loss = 2505.22733154 Train_Accuracy 0.044 \n",
      "\t 10 Loss = 106.673841036 Train_Accuracy 0.967 \n",
      "\t 20 Loss = 113.324669629 Train_Accuracy 0.959 \n",
      "\t 30 Loss = 96.6804435734 Train_Accuracy 0.971 \n",
      "\t 38 Loss = 101.444243753 Train_Accuracy 0.966 \n",
      "4 0.963166666667\n",
      "\t 0 Loss = 2307.94266391 Train_Accuracy 0.141 \n",
      "\t 10 Loss = 127.746775409 Train_Accuracy 0.964 \n",
      "\t 20 Loss = 79.7622878963 Train_Accuracy 0.979 \n",
      "\t 30 Loss = 77.7754721014 Train_Accuracy 0.972 \n",
      "\t 31 Loss = 105.790172045 Train_Accuracy 0.964 \n",
      "5 0.966916666667\n",
      "\t 0 Loss = 2309.89015383 Train_Accuracy 0.145 \n",
      "\t 10 Loss = 106.335408481 Train_Accuracy 0.971 \n",
      "\t 20 Loss = 79.4501970304 Train_Accuracy 0.977 \n",
      "\t 30 Loss = 100.21391171 Train_Accuracy 0.975 \n",
      "\t 40 Loss = 79.342960453 Train_Accuracy 0.978 \n",
      "\t 50 Loss = 73.6155339248 Train_Accuracy 0.978 \n",
      "\t 60 Loss = 91.590371825 Train_Accuracy 0.972 \n",
      "\t 70 Loss = 89.6938180891 Train_Accuracy 0.969 \n",
      "\t 80 Loss = 104.492170008 Train_Accuracy 0.962 \n",
      "\t 90 Loss = 92.3373286164 Train_Accuracy 0.974 \n",
      "\t 99 Loss = 84.7133467054 Train_Accuracy 0.969 \n",
      "1 0.966416666667\n",
      "\t 0 Loss = 2351.61836774 Train_Accuracy 0.05 \n",
      "\t 10 Loss = 138.677998255 Train_Accuracy 0.957 \n",
      "\t 20 Loss = 100.88307776 Train_Accuracy 0.971 \n",
      "\t 30 Loss = 81.0298066869 Train_Accuracy 0.974 \n",
      "\t 40 Loss = 101.447438304 Train_Accuracy 0.967 \n",
      "\t 50 Loss = 107.825778699 Train_Accuracy 0.965 \n",
      "\t 60 Loss = 88.2586265447 Train_Accuracy 0.974 \n",
      "\t 70 Loss = 90.9887462332 Train_Accuracy 0.971 \n",
      "\t 80 Loss = 92.1776201933 Train_Accuracy 0.97 \n",
      "\t 90 Loss = 77.1135425967 Train_Accuracy 0.97 \n",
      "\t 99 Loss = 77.2612184968 Train_Accuracy 0.98 \n",
      "2 0.969166666667\n",
      "\t 0 Loss = 2350.66674423 Train_Accuracy 0.086 \n",
      "\t 10 Loss = 158.750571668 Train_Accuracy 0.955 \n",
      "\t 20 Loss = 84.9734586811 Train_Accuracy 0.97 \n",
      "\t 30 Loss = 95.8832190602 Train_Accuracy 0.964 \n",
      "\t 40 Loss = 107.216868083 Train_Accuracy 0.966 \n",
      "\t 50 Loss = 82.3988776679 Train_Accuracy 0.976 \n",
      "\t 60 Loss = 99.6929020712 Train_Accuracy 0.97 \n",
      "\t 70 Loss = 90.4125876854 Train_Accuracy 0.972 \n",
      "\t 80 Loss = 74.0865512549 Train_Accuracy 0.983 \n",
      "\t 90 Loss = 76.3054284844 Train_Accuracy 0.978 \n",
      "\t 99 Loss = 94.3292187882 Train_Accuracy 0.975 \n",
      "3 0.9635\n",
      "\t 0 Loss = 2412.18026324 Train_Accuracy 0.097 \n",
      "\t 10 Loss = 132.794117353 Train_Accuracy 0.96 \n",
      "\t 20 Loss = 115.543999425 Train_Accuracy 0.968 \n",
      "\t 30 Loss = 99.5212564496 Train_Accuracy 0.969 \n",
      "\t 40 Loss = 96.342603067 Train_Accuracy 0.964 \n",
      "\t 50 Loss = 70.4307809288 Train_Accuracy 0.973 \n",
      "\t 60 Loss = 117.109104744 Train_Accuracy 0.96 \n",
      "\t 70 Loss = 86.4114686507 Train_Accuracy 0.975 \n",
      "\t 80 Loss = 88.0298998948 Train_Accuracy 0.973 \n",
      "\t 90 Loss = 73.2365953228 Train_Accuracy 0.973 \n",
      "\t 99 Loss = 82.0660150824 Train_Accuracy 0.974 \n",
      "4 0.965083333333\n",
      "\t 0 Loss = 2376.72654066 Train_Accuracy 0.08 \n",
      "\t 10 Loss = 130.308597234 Train_Accuracy 0.963 \n",
      "\t 20 Loss = 103.559763124 Train_Accuracy 0.966 \n",
      "\t 30 Loss = 76.1558779412 Train_Accuracy 0.976 \n",
      "\t 40 Loss = 91.8002592032 Train_Accuracy 0.966 \n",
      "\t 50 Loss = 91.7494533299 Train_Accuracy 0.97 \n",
      "\t 60 Loss = 90.9411060239 Train_Accuracy 0.972 \n",
      "\t 70 Loss = 80.8801888633 Train_Accuracy 0.978 \n",
      "\t 80 Loss = 94.4391389213 Train_Accuracy 0.97 \n",
      "\t 90 Loss = 88.5731663115 Train_Accuracy 0.968 \n",
      "\t 99 Loss = 62.9993452456 Train_Accuracy 0.977 \n",
      "5 0.9655\n",
      "\t 0 Loss = 2412.73874581 Train_Accuracy 0.075 \n",
      "\t 10 Loss = 121.718911762 Train_Accuracy 0.962 \n",
      "\t 20 Loss = 107.92272257 Train_Accuracy 0.964 \n",
      "\t 30 Loss = 111.824077922 Train_Accuracy 0.964 \n",
      "\t 40 Loss = 93.9202330002 Train_Accuracy 0.969 \n",
      "\t 50 Loss = 120.49769886 Train_Accuracy 0.962 \n",
      "\t 60 Loss = 76.0371286441 Train_Accuracy 0.98 \n",
      "\t 70 Loss = 103.86676389 Train_Accuracy 0.977 \n",
      "\t 80 Loss = 75.3200041457 Train_Accuracy 0.978 \n",
      "\t 90 Loss = 91.2331791401 Train_Accuracy 0.969 \n",
      "\t 99 Loss = 86.7611587837 Train_Accuracy 0.971 \n",
      "1 0.968916666667\n",
      "\t 0 Loss = 2497.56286388 Train_Accuracy 0.064 \n",
      "\t 10 Loss = 99.4299920281 Train_Accuracy 0.974 \n",
      "\t 20 Loss = 110.798176038 Train_Accuracy 0.962 \n",
      "\t 30 Loss = 107.829386859 Train_Accuracy 0.967 \n",
      "\t 40 Loss = 79.5151544858 Train_Accuracy 0.976 \n",
      "\t 50 Loss = 104.103488209 Train_Accuracy 0.969 \n",
      "\t 60 Loss = 75.0276602612 Train_Accuracy 0.975 \n",
      "\t 70 Loss = 79.0560684629 Train_Accuracy 0.974 \n",
      "\t 80 Loss = 75.2866948191 Train_Accuracy 0.976 \n",
      "\t 90 Loss = 89.9780637825 Train_Accuracy 0.972 \n",
      "\t 99 Loss = 75.6596338206 Train_Accuracy 0.967 \n",
      "2 0.9645\n",
      "\t 0 Loss = 2353.00941214 Train_Accuracy 0.09 \n",
      "\t 10 Loss = 104.745701975 Train_Accuracy 0.966 \n",
      "\t 20 Loss = 90.884986926 Train_Accuracy 0.97 \n",
      "\t 30 Loss = 100.900125325 Train_Accuracy 0.966 \n",
      "\t 40 Loss = 76.7282238231 Train_Accuracy 0.975 \n",
      "\t 45 Loss = 101.513113895 Train_Accuracy 0.969 \n",
      "3 0.96525\n",
      "\t 0 Loss = 2445.87461241 Train_Accuracy 0.089 \n",
      "\t 10 Loss = 137.178707473 Train_Accuracy 0.961 \n",
      "\t 20 Loss = 92.4793290329 Train_Accuracy 0.973 \n",
      "\t 30 Loss = 114.462651793 Train_Accuracy 0.96 \n",
      "\t 40 Loss = 74.2008670964 Train_Accuracy 0.973 \n",
      "\t 50 Loss = 83.0172282495 Train_Accuracy 0.973 \n",
      "\t 60 Loss = 92.5793063547 Train_Accuracy 0.975 \n",
      "\t 70 Loss = 96.3002805017 Train_Accuracy 0.961 \n",
      "\t 80 Loss = 86.3925078004 Train_Accuracy 0.98 \n",
      "\t 90 Loss = 77.6171782618 Train_Accuracy 0.972 \n",
      "\t 99 Loss = 87.4246819029 Train_Accuracy 0.973 \n",
      "4 0.965583333333\n",
      "\t 0 Loss = 2388.30212453 Train_Accuracy 0.085 \n",
      "\t 10 Loss = 112.00521656 Train_Accuracy 0.968 \n",
      "\t 20 Loss = 97.4374728708 Train_Accuracy 0.977 \n",
      "\t 30 Loss = 89.0264081913 Train_Accuracy 0.977 \n",
      "\t 40 Loss = 83.0605357428 Train_Accuracy 0.974 \n",
      "\t 50 Loss = 93.9349175579 Train_Accuracy 0.97 \n",
      "\t 60 Loss = 79.8968651773 Train_Accuracy 0.98 \n",
      "\t 70 Loss = 63.0525949093 Train_Accuracy 0.975 \n",
      "\t 80 Loss = 102.353836639 Train_Accuracy 0.973 \n",
      "\t 90 Loss = 85.2477389347 Train_Accuracy 0.976 \n",
      "\t 99 Loss = 90.989518012 Train_Accuracy 0.973 \n",
      "5 0.9665\n",
      "\t 0 Loss = 2284.73645901 Train_Accuracy 0.11 \n",
      "\t 10 Loss = 125.190238216 Train_Accuracy 0.96 \n",
      "\t 20 Loss = 93.2654751418 Train_Accuracy 0.975 \n",
      "\t 30 Loss = 107.044748665 Train_Accuracy 0.969 \n",
      "\t 40 Loss = 86.4945912547 Train_Accuracy 0.978 \n",
      "\t 50 Loss = 95.1050630131 Train_Accuracy 0.97 \n",
      "\t 60 Loss = 105.544413046 Train_Accuracy 0.969 \n",
      "\t 70 Loss = 93.7182280965 Train_Accuracy 0.97 \n",
      "\t 80 Loss = 72.8895763283 Train_Accuracy 0.977 \n",
      "\t 90 Loss = 85.8570665709 Train_Accuracy 0.971 \n",
      "\t 99 Loss = 87.7353035164 Train_Accuracy 0.975 \n",
      "1 0.965416666667\n",
      "\t 0 Loss = 2371.01821279 Train_Accuracy 0.166 \n",
      "\t 10 Loss = 125.227033705 Train_Accuracy 0.97 \n",
      "\t 20 Loss = 123.556436954 Train_Accuracy 0.957 \n",
      "\t 30 Loss = 100.383422454 Train_Accuracy 0.963 \n",
      "\t 40 Loss = 66.7685482928 Train_Accuracy 0.98 \n",
      "\t 50 Loss = 116.837766458 Train_Accuracy 0.966 \n",
      "\t 60 Loss = 58.9035671382 Train_Accuracy 0.982 \n",
      "\t 70 Loss = 89.6778131998 Train_Accuracy 0.965 \n",
      "\t 80 Loss = 78.531175162 Train_Accuracy 0.977 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 90 Loss = 90.3925540946 Train_Accuracy 0.968 \n",
      "\t 99 Loss = 72.7022778505 Train_Accuracy 0.977 \n",
      "2 0.966166666667\n",
      "\t 0 Loss = 2388.16993443 Train_Accuracy 0.085 \n",
      "\t 10 Loss = 119.305221127 Train_Accuracy 0.966 \n",
      "\t 20 Loss = 107.770562063 Train_Accuracy 0.97 \n",
      "\t 30 Loss = 106.802842737 Train_Accuracy 0.969 \n",
      "\t 40 Loss = 88.4442387743 Train_Accuracy 0.975 \n",
      "\t 50 Loss = 79.7961908414 Train_Accuracy 0.979 \n",
      "\t 60 Loss = 81.6976464758 Train_Accuracy 0.977 \n",
      "\t 70 Loss = 120.848059898 Train_Accuracy 0.971 \n",
      "\t 80 Loss = 104.317817184 Train_Accuracy 0.967 \n",
      "\t 90 Loss = 93.9221202845 Train_Accuracy 0.97 \n",
      "\t 99 Loss = 93.5227499975 Train_Accuracy 0.972 \n",
      "3 0.968\n",
      "\t 0 Loss = 2444.99264353 Train_Accuracy 0.083 \n",
      "\t 10 Loss = 146.111151133 Train_Accuracy 0.955 \n",
      "\t 20 Loss = 113.105192161 Train_Accuracy 0.96 \n",
      "\t 30 Loss = 86.3600833794 Train_Accuracy 0.974 \n",
      "\t 40 Loss = 143.773745788 Train_Accuracy 0.957 \n",
      "\t 50 Loss = 100.319152081 Train_Accuracy 0.97 \n",
      "\t 60 Loss = 112.132092715 Train_Accuracy 0.961 \n",
      "\t 70 Loss = 85.9598112792 Train_Accuracy 0.971 \n",
      "\t 80 Loss = 75.329793679 Train_Accuracy 0.977 \n",
      "\t 85 Loss = 77.1854130886 Train_Accuracy 0.976 \n",
      "4 0.968916666667\n",
      "\t 0 Loss = 2382.6365295 Train_Accuracy 0.1 \n",
      "\t 10 Loss = 112.748015705 Train_Accuracy 0.967 \n",
      "\t 20 Loss = 91.3799900969 Train_Accuracy 0.97 \n",
      "\t 30 Loss = 99.6092182601 Train_Accuracy 0.968 \n",
      "\t 40 Loss = 121.574715545 Train_Accuracy 0.958 \n",
      "\t 50 Loss = 96.1360416573 Train_Accuracy 0.971 \n",
      "\t 60 Loss = 69.0407099391 Train_Accuracy 0.979 \n",
      "\t 70 Loss = 97.9528618467 Train_Accuracy 0.97 \n",
      "\t 80 Loss = 66.757459176 Train_Accuracy 0.98 \n",
      "\t 90 Loss = 87.0260514389 Train_Accuracy 0.966 \n",
      "\t 99 Loss = 73.7724481036 Train_Accuracy 0.977 \n",
      "5 0.96475\n"
     ]
    }
   ],
   "source": [
    "block_size = 4\n",
    "orientation = np.array([1, 2, 4, 8])\n",
    "accuracy = np.zeros(4)\n",
    "for i in range(len(orientation)):\n",
    "    model = mnist.ImageFeatureModel(\n",
    "        LogisticGDClassifier(), size=block_size, orientations=orientation[i])\n",
    "    accuracy[i] = validate_model(model, 5, images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(orientation,accuracy)\n",
    "plt.title(\"Number of orientations vs Validation accuracy\")\n",
    "plt.xlabel(\"Orientation\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Problem 5.2 </div>\n",
    "\n",
    "Fit the model with the optimal number of orientations to the full MNIST data set and estimate its accuracy on the MNIST test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:16:52.002722Z",
     "start_time": "2018-03-02T03:14:27.259850Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= mnist.ImageFeatureModel(LogisticGDClassifier(),size=block_size,orientations=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(images,labels,images_test,labels_test)\n",
    "Y_predicted=model.predict(images_test)\n",
    "print(\"accuracy\",np.mean(Y_predicted==labels_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
